{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f6b03474",
      "metadata": {
        "id": "f6b03474"
      },
      "source": [
        "[Dataset](https://www.kaggle.com/arashnic/building-sites-power-consumption-dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "BeB-5Vb54j22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeB-5Vb54j22",
        "outputId": "f350c6a5-c497-4570-c4cf-14f0a8f42153"
      },
      "outputs": [],
      "source": [
        "#!kaggle datasets download -d arashnic/building-sites-power-consumption-dataset\n",
        "#!unzip building-sites-power-consumption-dataset.zip -d ./dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc3e4402",
      "metadata": {},
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sWbXCGozBRNW",
      "metadata": {
        "id": "sWbXCGozBRNW"
      },
      "source": [
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "kmxpysFu7zjH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmxpysFu7zjH",
        "outputId": "db2717d5-22be-4fa8-99fb-3f9ea90e7e1b"
      },
      "outputs": [],
      "source": [
        "# data elaboration functions\n",
        "import pandas as pd\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "# datetime functions\n",
        "import datetime as dt\n",
        "\n",
        "# file management functions\n",
        "import os\n",
        "import sys\n",
        "import opendatasets as od\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "# plot functions\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# data science functions\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import joblib\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# configuration file\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "from Configuration.config import cfg_path\n",
        "\n",
        "# custom functions\n",
        "from Code.Plotting.plots import Plots\n",
        "from Code.Regressors.regressors import Regressors\n",
        "from Code.Regressors.temperatures import Temperatures\n",
        "from Code.Scoring.scoring import Scoring\n",
        "from Code.Scoring.train_test import TrainTest\n",
        "from Code.Scoring.train import Training\n",
        "from Code.Scoring.forecast import Forecasting\n",
        "from Code.Scoring.kpi import Kpi\n",
        "from Code.Scoring.scoring import Scoring\n",
        "from Code.Utils.utils import Utils\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dc26b7b",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "458162d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "#od.download(\"https://www.kaggle.com/arashnic/building-sites-power-consumption-dataset/download\")\n",
        "root = Path(os.getcwd()).parent\n",
        "dataset_path = os.path.join(root, cfg_path.data_dir.input_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4Q-4BToWB7LC",
      "metadata": {
        "id": "4Q-4BToWB7LC"
      },
      "source": [
        "## Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d7e24623",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7e24623",
        "outputId": "30507a03-42e3-4f9e-8b2b-bccb623a06c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train columns:  ['obs_id', 'site_id', 'timestamp', 'forecast_id', 'value']\n",
            "NaNs: 86601\n",
            "Metadata columns:  ['site_id', 'surface', 'sampling', 'base_temperature', 'monday_is_day_off', 'tuesday_is_day_off', 'wednesday_is_day_off', 'thursday_is_day_off', 'friday_is_day_off', 'saturday_is_day_off', 'sunday_is_day_off']\n",
            "NaNs: 0\n",
            "Weather columns:  ['timestamp', 'temperature', 'distance', 'site_id']\n",
            "NaNs: 0\n"
          ]
        }
      ],
      "source": [
        "df_train_data = pd.read_csv(os.path.join(dataset_path, \"power-laws-forecasting-energy-consumption-training-data.csv\"), sep=\";\", parse_dates=[\"Timestamp\"])\n",
        "df_train_data = Utils.columns_camel_to_snake(df_train_data)\n",
        "print(\"Train columns: \", list(df_train_data.columns))\n",
        "print(\"NaNs:\", df_train_data.isna().sum().values.sum())\n",
        "\n",
        "df_metadata = pd.read_csv(os.path.join(dataset_path, \"power-laws-forecasting-energy-consumption-metadata.csv\"), sep=\";\")\n",
        "df_metadata = Utils.columns_camel_to_snake(df_metadata)\n",
        "print(\"Metadata columns: \", list(df_metadata.columns))\n",
        "print(\"NaNs:\", df_metadata.isna().sum().values.sum())\n",
        "\n",
        "df_weather = pd.read_csv(os.path.join(dataset_path, \"power-laws-forecasting-energy-consumption-weather.csv\"), sep=\";\", parse_dates=[\"Timestamp\"])\n",
        "df_weather = Utils.columns_camel_to_snake(df_weather)\n",
        "print(\"Weather columns: \", list(df_weather.columns))\n",
        "print(\"NaNs:\", df_weather.isna().sum().values.sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ShqG6YJGmBk",
      "metadata": {
        "id": "1ShqG6YJGmBk"
      },
      "source": [
        "# Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f23ed7fb",
      "metadata": {},
      "source": [
        "## Parameter setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0ddada30",
      "metadata": {},
      "outputs": [],
      "source": [
        "id = 'site_id'\n",
        "list_unique_id = ['site_id', 'timestamp']\n",
        "list_temp = ['temp']\n",
        "y = 'value'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2799c9d5",
      "metadata": {},
      "source": [
        "#### Setting forecast end date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5f55942a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make sure to have all regressors available until forecast_end_date (temperatures, etc)\n",
        "forecast_end_date = '2022-12-31'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08af66c3",
      "metadata": {},
      "source": [
        "## Plotting y series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "23685319",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[42, 43, 40, 41, 63, 66, 67, 68, 64, 65, 69, 70, 72, 73, 115, 119, 116, 117, 118, 59, 60, 62, 61, 112, 109, 110, 111, 8, 9, 25, 26, 46, 47, 48, 49, 106, 107, 100, 101, 102, 105, 50, 51, 52, 53, 108, 14, 10, 11, 12, 13, 22, 23, 57, 54, 58, 93, 94, 96, 98, 99, 92, 44, 45, 88, 87, 89, 90, 84, 85, 86, 78, 83, 228, 222, 223, 224, 225, 226, 227, 215, 229, 230, 273, 276, 271, 274, 275, 272, 74, 77, 76, 75, 218, 219, 221, 233, 234, 269, 270, 235, 236, 237, 216, 217, 204, 209, 261, 262, 263, 264, 265, 266, 267, 268, 232, 212, 213, 205, 206, 207, 208, 210, 211, 260, 259, 255, 256, 257, 231, 252, 254, 250, 251, 253, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 123, 124, 125, 126, 121, 122, 120, 127, 128, 129, 200, 201, 199, 141, 140, 135, 136, 139, 202, 203, 151, 149, 152, 146, 148, 150, 190, 191, 19, 167, 162, 173, 171, 172, 169, 170, 163, 164, 165, 143, 145, 142, 197, 194, 195, 196, 192, 193, 160, 161, 153, 154, 155, 156, 157, 158, 159, 198, 175, 174, 183, 184, 185, 186, 189, 181, 182, 130, 131, 134, 132, 176, 180, 177, 178, 280, 281, 277, 287, 288, 278, 279, 294, 295, 292, 293, 289, 290, 286, 285, 284, 298, 299, 300, 283, 297, 302, 301, 303, 304, 305, 282, 6, 7, 15, 16, 2, 1, 3, 5, 20, 21, 17, 18, 27, 33, 29, 32, 38, 39, 34]\n"
          ]
        }
      ],
      "source": [
        "# Print available ids and choose which one to plot \n",
        "print(list(df_train_data[id].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6e669264",
      "metadata": {},
      "outputs": [],
      "source": [
        "list_ids_to_plot = [49, 12, 63, 44]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "109aaf82",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting id: 49 as 1 of 4\n",
            "find_date, date_col found: ['timestamp']\n",
            "sliding_line_plot: plotting Value site_id 49\n",
            "Plotting id: 12 as 2 of 4\n",
            "find_date, date_col found: ['timestamp']\n",
            "sliding_line_plot: plotting Value site_id 12\n",
            "Plotting id: 63 as 3 of 4\n",
            "find_date, date_col found: ['timestamp']\n",
            "sliding_line_plot: plotting Value site_id 63\n",
            "Plotting id: 44 as 4 of 4\n",
            "find_date, date_col found: ['timestamp']\n",
            "sliding_line_plot: plotting Value site_id 44\n"
          ]
        }
      ],
      "source": [
        "count = 1\n",
        "for i in list_ids_to_plot:\n",
        "    print('Plotting id:', i, 'as', count, 'of', len(list_ids_to_plot))\n",
        "    plot = Plots.sliding_line_plot(df_train_data, y, id, i, chart_title=\"\")\n",
        "    plot.write_html(os.path.join(root, cfg_path.data_dir.plot_path, id + '_' + str(i) + \".html\"))\n",
        "    count = count + 1 "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0be27d0",
      "metadata": {},
      "source": [
        "## Dealing with NAs and aggregating at a chosen frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e88444e",
      "metadata": {},
      "source": [
        "Create a full time sequence on a chosen frequency and aggregate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26de9cc1",
      "metadata": {},
      "source": [
        "#### Consumption data (y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "77429654",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "find_date, date_col found: ['timestamp']\n",
            "List ids: [42, 43, 40, 41, 63, 66, 67, 68, 64, 65, 69, 70, 72, 73, 115, 119, 116, 117, 118, 59, 60, 62, 61, 112, 109, 110, 111, 8, 9, 25, 26, 46, 47, 48, 49, 106, 107, 100, 101, 102, 105, 50, 51, 52, 53, 108, 14, 10, 11, 12, 13, 22, 23, 57, 54, 58, 93, 94, 96, 98, 99, 92, 44, 45, 88, 87, 89, 90, 84, 85, 86, 78, 83, 228, 222, 223, 224, 225, 226, 227, 215, 229, 230, 273, 276, 271, 274, 275, 272, 74, 77, 76, 75, 218, 219, 221, 233, 234, 269, 270, 235, 236, 237, 216, 217, 204, 209, 261, 262, 263, 264, 265, 266, 267, 268, 232, 212, 213, 205, 206, 207, 208, 210, 211, 260, 259, 255, 256, 257, 231, 252, 254, 250, 251, 253, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 123, 124, 125, 126, 121, 122, 120, 127, 128, 129, 200, 201, 199, 141, 140, 135, 136, 139, 202, 203, 151, 149, 152, 146, 148, 150, 190, 191, 19, 167, 162, 173, 171, 172, 169, 170, 163, 164, 165, 143, 145, 142, 197, 194, 195, 196, 192, 193, 160, 161, 153, 154, 155, 156, 157, 158, 159, 198, 175, 174, 183, 184, 185, 186, 189, 181, 182, 130, 131, 134, 132, 176, 180, 177, 178, 280, 281, 277, 287, 288, 278, 279, 294, 295, 292, 293, 289, 290, 286, 285, 284, 298, 299, 300, 283, 297, 302, 301, 303, 304, 305, 282, 6, 7, 15, 16, 2, 1, 3, 5, 20, 21, 17, 18, 27, 33, 29, 32, 38, 39, 34]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "267"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df_train_data\n",
        "df_train_data.head()\n",
        "date_var = Utils.find_date(df_train_data)\n",
        "print('List ids:', list(df_train_data[id].unique()))\n",
        "len(list(df_train_data[id].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f711e287",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "resample_data: variable obs_id\n",
            "resample_data: variable obs_id completed\n",
            "resample_data: variable forecast_id\n",
            "resample_data: variable forecast_id completed\n",
            "resample_data: variable value\n",
            "resample_data: variable value completed\n",
            "                       timestamp     obs_id  site_id  forecast_id  \\\n",
            "0      2015-11-02 00:00:00+00:00  3187477.0       42       1080.0   \n",
            "1      2015-11-03 00:00:00+00:00  1309542.0       42       1080.0   \n",
            "2      2015-11-04 00:00:00+00:00  6998589.0       42       1080.0   \n",
            "3      2015-11-05 00:00:00+00:00  5708558.0       42       1080.0   \n",
            "4      2015-11-06 00:00:00+00:00  6931527.0       42       1080.0   \n",
            "...                          ...        ...      ...          ...   \n",
            "188662 2015-02-12 00:00:00+00:00   954528.0       34        981.0   \n",
            "188663 2015-02-13 00:00:00+00:00  6319073.0       34        981.0   \n",
            "188664 2015-02-14 00:00:00+00:00   849485.0       34        981.0   \n",
            "188665 2015-02-15 00:00:00+00:00   141866.0       34        981.0   \n",
            "188666 2015-02-16 00:00:00+00:00  7593648.0       34        981.0   \n",
            "\n",
            "               value  \n",
            "0       6.370880e+05  \n",
            "1       1.006306e+06  \n",
            "2       1.008557e+06  \n",
            "3       1.017008e+06  \n",
            "4       1.028142e+06  \n",
            "...              ...  \n",
            "188662  2.165641e+04  \n",
            "188663  2.124533e+04  \n",
            "188664  1.011816e+04  \n",
            "188665  9.968675e+03  \n",
            "188666  1.181853e+04  \n",
            "\n",
            "[188667 rows x 5 columns]\n",
            "List ids after resampling: [42, 43, 40, 41, 63, 66, 67, 68, 64, 65, 69, 70, 72, 73, 115, 119, 116, 117, 118, 59, 60, 62, 61, 112, 109, 110, 111, 8, 9, 25, 26, 46, 47, 48, 49, 106, 107, 100, 101, 102, 105, 50, 51, 52, 53, 108, 14, 10, 11, 12, 13, 22, 23, 57, 54, 58, 93, 94, 96, 98, 99, 92, 44, 45, 88, 87, 89, 90, 84, 85, 86, 78, 83, 228, 222, 223, 224, 225, 226, 227, 215, 229, 230, 273, 276, 271, 274, 275, 272, 74, 77, 76, 75, 218, 219, 221, 233, 234, 269, 270, 235, 236, 237, 216, 217, 204, 209, 261, 262, 263, 264, 265, 266, 267, 268, 232, 212, 213, 205, 206, 207, 208, 210, 211, 260, 259, 255, 256, 257, 231, 252, 254, 250, 251, 253, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 123, 124, 125, 126, 121, 122, 120, 127, 128, 129, 200, 201, 199, 141, 140, 135, 136, 139, 202, 203, 151, 149, 152, 146, 148, 150, 190, 191, 19, 167, 162, 173, 171, 172, 169, 170, 163, 164, 165, 143, 145, 142, 197, 194, 195, 196, 192, 193, 160, 161, 153, 154, 155, 156, 157, 158, 159, 198, 175, 174, 183, 184, 185, 186, 189, 181, 182, 130, 131, 134, 132, 176, 180, 177, 178, 280, 281, 277, 287, 288, 278, 279, 294, 295, 292, 293, 289, 290, 286, 285, 284, 298, 299, 300, 283, 297, 302, 301, 303, 304, 305, 282, 6, 7, 15, 16, 2, 1, 3, 5, 20, 21, 17, 18, 27, 33, 29, 32, 38, 39, 34]\n"
          ]
        }
      ],
      "source": [
        "# Resampling function aggregates data in a dataframe with a chosen function, that can vary depending on the variable\n",
        "# i.e. temperatures when aggregated should be averaged, consumption should be summed, dummy variables should be pick as 'first'\n",
        "\n",
        "df_train_data[date_var].apply(lambda x: x.tz_localize(None))\n",
        "sampling = dt.timedelta(days=1)\n",
        "dict_grouping = {'obs_id': 'first', 'forecast_id': 'first', 'value': 'sum'}\n",
        "df_resampled = Utils.resample_data(df_train_data, id, date_var, sampling, dict_grouping)\n",
        "print('List ids after resampling:', list(df_resampled[id].unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fecd0d49",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding sequence to serie 42 as 1 of 267\n",
            "Adding sequence to serie 43 as 2 of 267\n",
            "Adding sequence to serie 40 as 3 of 267\n",
            "Adding sequence to serie 41 as 4 of 267\n",
            "Adding sequence to serie 63 as 5 of 267\n",
            "Adding sequence to serie 66 as 6 of 267\n",
            "Adding sequence to serie 67 as 7 of 267\n",
            "Adding sequence to serie 68 as 8 of 267\n",
            "Adding sequence to serie 64 as 9 of 267\n",
            "Adding sequence to serie 65 as 10 of 267\n",
            "Adding sequence to serie 69 as 11 of 267\n",
            "Adding sequence to serie 70 as 12 of 267\n",
            "Adding sequence to serie 72 as 13 of 267\n",
            "Adding sequence to serie 73 as 14 of 267\n",
            "Adding sequence to serie 115 as 15 of 267\n",
            "Adding sequence to serie 119 as 16 of 267\n",
            "Adding sequence to serie 116 as 17 of 267\n",
            "Adding sequence to serie 117 as 18 of 267\n",
            "Adding sequence to serie 118 as 19 of 267\n",
            "Adding sequence to serie 59 as 20 of 267\n",
            "Adding sequence to serie 60 as 21 of 267\n",
            "Adding sequence to serie 62 as 22 of 267\n",
            "Adding sequence to serie 61 as 23 of 267\n",
            "Adding sequence to serie 112 as 24 of 267\n",
            "Adding sequence to serie 109 as 25 of 267\n",
            "Adding sequence to serie 110 as 26 of 267\n",
            "Adding sequence to serie 111 as 27 of 267\n",
            "Adding sequence to serie 8 as 28 of 267\n",
            "Adding sequence to serie 9 as 29 of 267\n",
            "Adding sequence to serie 25 as 30 of 267\n",
            "Adding sequence to serie 26 as 31 of 267\n",
            "Adding sequence to serie 46 as 32 of 267\n",
            "Adding sequence to serie 47 as 33 of 267\n",
            "Adding sequence to serie 48 as 34 of 267\n",
            "Adding sequence to serie 49 as 35 of 267\n",
            "Adding sequence to serie 106 as 36 of 267\n",
            "Adding sequence to serie 107 as 37 of 267\n",
            "Adding sequence to serie 100 as 38 of 267\n",
            "Adding sequence to serie 101 as 39 of 267\n",
            "Adding sequence to serie 102 as 40 of 267\n",
            "Adding sequence to serie 105 as 41 of 267\n",
            "Adding sequence to serie 50 as 42 of 267\n",
            "Adding sequence to serie 51 as 43 of 267\n",
            "Adding sequence to serie 52 as 44 of 267\n",
            "Adding sequence to serie 53 as 45 of 267\n",
            "Adding sequence to serie 108 as 46 of 267\n",
            "Adding sequence to serie 14 as 47 of 267\n",
            "Adding sequence to serie 10 as 48 of 267\n",
            "Adding sequence to serie 11 as 49 of 267\n",
            "Adding sequence to serie 12 as 50 of 267\n",
            "Adding sequence to serie 13 as 51 of 267\n",
            "Adding sequence to serie 22 as 52 of 267\n",
            "Adding sequence to serie 23 as 53 of 267\n",
            "Adding sequence to serie 57 as 54 of 267\n",
            "Adding sequence to serie 54 as 55 of 267\n",
            "Adding sequence to serie 58 as 56 of 267\n",
            "Adding sequence to serie 93 as 57 of 267\n",
            "Adding sequence to serie 94 as 58 of 267\n",
            "Adding sequence to serie 96 as 59 of 267\n",
            "Adding sequence to serie 98 as 60 of 267\n",
            "Adding sequence to serie 99 as 61 of 267\n",
            "Adding sequence to serie 92 as 62 of 267\n",
            "Adding sequence to serie 44 as 63 of 267\n",
            "Adding sequence to serie 45 as 64 of 267\n",
            "Adding sequence to serie 88 as 65 of 267\n",
            "Adding sequence to serie 87 as 66 of 267\n",
            "Adding sequence to serie 89 as 67 of 267\n",
            "Adding sequence to serie 90 as 68 of 267\n",
            "Adding sequence to serie 84 as 69 of 267\n",
            "Adding sequence to serie 85 as 70 of 267\n",
            "Adding sequence to serie 86 as 71 of 267\n",
            "Adding sequence to serie 78 as 72 of 267\n",
            "Adding sequence to serie 83 as 73 of 267\n",
            "Adding sequence to serie 228 as 74 of 267\n",
            "Adding sequence to serie 222 as 75 of 267\n",
            "Adding sequence to serie 223 as 76 of 267\n",
            "Adding sequence to serie 224 as 77 of 267\n",
            "Adding sequence to serie 225 as 78 of 267\n",
            "Adding sequence to serie 226 as 79 of 267\n",
            "Adding sequence to serie 227 as 80 of 267\n",
            "Adding sequence to serie 215 as 81 of 267\n",
            "Adding sequence to serie 229 as 82 of 267\n",
            "Adding sequence to serie 230 as 83 of 267\n",
            "Adding sequence to serie 273 as 84 of 267\n",
            "Adding sequence to serie 276 as 85 of 267\n",
            "Adding sequence to serie 271 as 86 of 267\n",
            "Adding sequence to serie 274 as 87 of 267\n",
            "Adding sequence to serie 275 as 88 of 267\n",
            "Adding sequence to serie 272 as 89 of 267\n",
            "Adding sequence to serie 74 as 90 of 267\n",
            "Adding sequence to serie 77 as 91 of 267\n",
            "Adding sequence to serie 76 as 92 of 267\n",
            "Adding sequence to serie 75 as 93 of 267\n",
            "Adding sequence to serie 218 as 94 of 267\n",
            "Adding sequence to serie 219 as 95 of 267\n",
            "Adding sequence to serie 221 as 96 of 267\n",
            "Adding sequence to serie 233 as 97 of 267\n",
            "Adding sequence to serie 234 as 98 of 267\n",
            "Adding sequence to serie 269 as 99 of 267\n",
            "Adding sequence to serie 270 as 100 of 267\n",
            "Adding sequence to serie 235 as 101 of 267\n",
            "Adding sequence to serie 236 as 102 of 267\n",
            "Adding sequence to serie 237 as 103 of 267\n",
            "Adding sequence to serie 216 as 104 of 267\n",
            "Adding sequence to serie 217 as 105 of 267\n",
            "Adding sequence to serie 204 as 106 of 267\n",
            "Adding sequence to serie 209 as 107 of 267\n",
            "Adding sequence to serie 261 as 108 of 267\n",
            "Adding sequence to serie 262 as 109 of 267\n",
            "Adding sequence to serie 263 as 110 of 267\n",
            "Adding sequence to serie 264 as 111 of 267\n",
            "Adding sequence to serie 265 as 112 of 267\n",
            "Adding sequence to serie 266 as 113 of 267\n",
            "Adding sequence to serie 267 as 114 of 267\n",
            "Adding sequence to serie 268 as 115 of 267\n",
            "Adding sequence to serie 232 as 116 of 267\n",
            "Adding sequence to serie 212 as 117 of 267\n",
            "Adding sequence to serie 213 as 118 of 267\n",
            "Adding sequence to serie 205 as 119 of 267\n",
            "Adding sequence to serie 206 as 120 of 267\n",
            "Adding sequence to serie 207 as 121 of 267\n",
            "Adding sequence to serie 208 as 122 of 267\n",
            "Adding sequence to serie 210 as 123 of 267\n",
            "Adding sequence to serie 211 as 124 of 267\n",
            "Adding sequence to serie 260 as 125 of 267\n",
            "Adding sequence to serie 259 as 126 of 267\n",
            "Adding sequence to serie 255 as 127 of 267\n",
            "Adding sequence to serie 256 as 128 of 267\n",
            "Adding sequence to serie 257 as 129 of 267\n",
            "Adding sequence to serie 231 as 130 of 267\n",
            "Adding sequence to serie 252 as 131 of 267\n",
            "Adding sequence to serie 254 as 132 of 267\n",
            "Adding sequence to serie 250 as 133 of 267\n",
            "Adding sequence to serie 251 as 134 of 267\n",
            "Adding sequence to serie 253 as 135 of 267\n",
            "Adding sequence to serie 238 as 136 of 267\n",
            "Adding sequence to serie 239 as 137 of 267\n",
            "Adding sequence to serie 240 as 138 of 267\n",
            "Adding sequence to serie 241 as 139 of 267\n",
            "Adding sequence to serie 243 as 140 of 267\n",
            "Adding sequence to serie 244 as 141 of 267\n",
            "Adding sequence to serie 245 as 142 of 267\n",
            "Adding sequence to serie 246 as 143 of 267\n",
            "Adding sequence to serie 247 as 144 of 267\n",
            "Adding sequence to serie 248 as 145 of 267\n",
            "Adding sequence to serie 249 as 146 of 267\n",
            "Adding sequence to serie 123 as 147 of 267\n",
            "Adding sequence to serie 124 as 148 of 267\n",
            "Adding sequence to serie 125 as 149 of 267\n",
            "Adding sequence to serie 126 as 150 of 267\n",
            "Adding sequence to serie 121 as 151 of 267\n",
            "Adding sequence to serie 122 as 152 of 267\n",
            "Adding sequence to serie 120 as 153 of 267\n",
            "Adding sequence to serie 127 as 154 of 267\n",
            "Adding sequence to serie 128 as 155 of 267\n",
            "Adding sequence to serie 129 as 156 of 267\n",
            "Adding sequence to serie 200 as 157 of 267\n",
            "Adding sequence to serie 201 as 158 of 267\n",
            "Adding sequence to serie 199 as 159 of 267\n",
            "Adding sequence to serie 141 as 160 of 267\n",
            "Adding sequence to serie 140 as 161 of 267\n",
            "Adding sequence to serie 135 as 162 of 267\n",
            "Adding sequence to serie 136 as 163 of 267\n",
            "Adding sequence to serie 139 as 164 of 267\n",
            "Adding sequence to serie 202 as 165 of 267\n",
            "Adding sequence to serie 203 as 166 of 267\n",
            "Adding sequence to serie 151 as 167 of 267\n",
            "Adding sequence to serie 149 as 168 of 267\n",
            "Adding sequence to serie 152 as 169 of 267\n",
            "Adding sequence to serie 146 as 170 of 267\n",
            "Adding sequence to serie 148 as 171 of 267\n",
            "Adding sequence to serie 150 as 172 of 267\n",
            "Adding sequence to serie 190 as 173 of 267\n",
            "Adding sequence to serie 191 as 174 of 267\n",
            "Adding sequence to serie 19 as 175 of 267\n",
            "Adding sequence to serie 167 as 176 of 267\n",
            "Adding sequence to serie 162 as 177 of 267\n",
            "Adding sequence to serie 173 as 178 of 267\n",
            "Adding sequence to serie 171 as 179 of 267\n",
            "Adding sequence to serie 172 as 180 of 267\n",
            "Adding sequence to serie 169 as 181 of 267\n",
            "Adding sequence to serie 170 as 182 of 267\n",
            "Adding sequence to serie 163 as 183 of 267\n",
            "Adding sequence to serie 164 as 184 of 267\n",
            "Adding sequence to serie 165 as 185 of 267\n",
            "Adding sequence to serie 143 as 186 of 267\n",
            "Adding sequence to serie 145 as 187 of 267\n",
            "Adding sequence to serie 142 as 188 of 267\n",
            "Adding sequence to serie 197 as 189 of 267\n",
            "Adding sequence to serie 194 as 190 of 267\n",
            "Adding sequence to serie 195 as 191 of 267\n",
            "Adding sequence to serie 196 as 192 of 267\n",
            "Adding sequence to serie 192 as 193 of 267\n",
            "Adding sequence to serie 193 as 194 of 267\n",
            "Adding sequence to serie 160 as 195 of 267\n",
            "Adding sequence to serie 161 as 196 of 267\n",
            "Adding sequence to serie 153 as 197 of 267\n",
            "Adding sequence to serie 154 as 198 of 267\n",
            "Adding sequence to serie 155 as 199 of 267\n",
            "Adding sequence to serie 156 as 200 of 267\n",
            "Adding sequence to serie 157 as 201 of 267\n",
            "Adding sequence to serie 158 as 202 of 267\n",
            "Adding sequence to serie 159 as 203 of 267\n",
            "Adding sequence to serie 198 as 204 of 267\n",
            "Adding sequence to serie 175 as 205 of 267\n",
            "Adding sequence to serie 174 as 206 of 267\n",
            "Adding sequence to serie 183 as 207 of 267\n",
            "Adding sequence to serie 184 as 208 of 267\n",
            "Adding sequence to serie 185 as 209 of 267\n",
            "Adding sequence to serie 186 as 210 of 267\n",
            "Adding sequence to serie 189 as 211 of 267\n",
            "Adding sequence to serie 181 as 212 of 267\n",
            "Adding sequence to serie 182 as 213 of 267\n",
            "Adding sequence to serie 130 as 214 of 267\n",
            "Adding sequence to serie 131 as 215 of 267\n",
            "Adding sequence to serie 134 as 216 of 267\n",
            "Adding sequence to serie 132 as 217 of 267\n",
            "Adding sequence to serie 176 as 218 of 267\n",
            "Adding sequence to serie 180 as 219 of 267\n",
            "Adding sequence to serie 177 as 220 of 267\n",
            "Adding sequence to serie 178 as 221 of 267\n",
            "Adding sequence to serie 280 as 222 of 267\n",
            "Adding sequence to serie 281 as 223 of 267\n",
            "Adding sequence to serie 277 as 224 of 267\n",
            "Adding sequence to serie 287 as 225 of 267\n",
            "Adding sequence to serie 288 as 226 of 267\n",
            "Adding sequence to serie 278 as 227 of 267\n",
            "Adding sequence to serie 279 as 228 of 267\n",
            "Adding sequence to serie 294 as 229 of 267\n",
            "Adding sequence to serie 295 as 230 of 267\n",
            "Adding sequence to serie 292 as 231 of 267\n",
            "Adding sequence to serie 293 as 232 of 267\n",
            "Adding sequence to serie 289 as 233 of 267\n",
            "Adding sequence to serie 290 as 234 of 267\n",
            "Adding sequence to serie 286 as 235 of 267\n",
            "Adding sequence to serie 285 as 236 of 267\n",
            "Adding sequence to serie 284 as 237 of 267\n",
            "Adding sequence to serie 298 as 238 of 267\n",
            "Adding sequence to serie 299 as 239 of 267\n",
            "Adding sequence to serie 300 as 240 of 267\n",
            "Adding sequence to serie 283 as 241 of 267\n",
            "Adding sequence to serie 297 as 242 of 267\n",
            "Adding sequence to serie 302 as 243 of 267\n",
            "Adding sequence to serie 301 as 244 of 267\n",
            "Adding sequence to serie 303 as 245 of 267\n",
            "Adding sequence to serie 304 as 246 of 267\n",
            "Adding sequence to serie 305 as 247 of 267\n",
            "Adding sequence to serie 282 as 248 of 267\n",
            "Adding sequence to serie 6 as 249 of 267\n",
            "Adding sequence to serie 7 as 250 of 267\n",
            "Adding sequence to serie 15 as 251 of 267\n",
            "Adding sequence to serie 16 as 252 of 267\n",
            "Adding sequence to serie 2 as 253 of 267\n",
            "Adding sequence to serie 1 as 254 of 267\n",
            "Adding sequence to serie 3 as 255 of 267\n",
            "Adding sequence to serie 5 as 256 of 267\n",
            "Adding sequence to serie 20 as 257 of 267\n",
            "Adding sequence to serie 21 as 258 of 267\n",
            "Adding sequence to serie 17 as 259 of 267\n",
            "Adding sequence to serie 18 as 260 of 267\n",
            "Adding sequence to serie 27 as 261 of 267\n",
            "Adding sequence to serie 33 as 262 of 267\n",
            "Adding sequence to serie 29 as 263 of 267\n",
            "Adding sequence to serie 32 as 264 of 267\n",
            "Adding sequence to serie 38 as 265 of 267\n",
            "Adding sequence to serie 39 as 266 of 267\n",
            "Adding sequence to serie 34 as 267 of 267\n",
            "add_seq: there are NO duplicates in sequence\n",
            "add_seq: there are NO duplicates when adding sequence\n",
            "Total serie to forecast: 698739\n"
          ]
        }
      ],
      "source": [
        "# Adding a full time sequence\n",
        "df_train_data = Utils.add_seq(df_resampled, date_var, serie = id, freq = sampling, end_date=forecast_end_date, start_date='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "650cf7b7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expected length of sequence is OK \n",
            "      site_id   count  expected_obs\n",
            "0          1  2617.0        2617.0\n",
            "1          2  2617.0        2617.0\n",
            "2          3  2617.0        2617.0\n",
            "3          5  2617.0        2617.0\n",
            "4          6  2617.0        2617.0\n",
            "..       ...     ...           ...\n",
            "262      301  2617.0        2617.0\n",
            "263      302  2617.0        2617.0\n",
            "264      303  2617.0        2617.0\n",
            "265      304  2617.0        2617.0\n",
            "266      305  2617.0        2617.0\n",
            "\n",
            "[267 rows x 3 columns]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>count</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>td</th>\n",
              "      <th>freq</th>\n",
              "      <th>expected_obs</th>\n",
              "      <th>mismatch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2617.0</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>2616 days</td>\n",
              "      <td>D</td>\n",
              "      <td>2617.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2617.0</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>2616 days</td>\n",
              "      <td>D</td>\n",
              "      <td>2617.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2617.0</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>2616 days</td>\n",
              "      <td>D</td>\n",
              "      <td>2617.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>2617.0</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>2616 days</td>\n",
              "      <td>D</td>\n",
              "      <td>2617.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>2617.0</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>2616 days</td>\n",
              "      <td>D</td>\n",
              "      <td>2617.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   site_id   count        min        max        td freq  expected_obs  \\\n",
              "0        1  2617.0 2015-11-02 2022-12-31 2616 days    D        2617.0   \n",
              "1        2  2617.0 2015-11-02 2022-12-31 2616 days    D        2617.0   \n",
              "2        3  2617.0 2015-11-02 2022-12-31 2616 days    D        2617.0   \n",
              "3        5  2617.0 2015-11-02 2022-12-31 2616 days    D        2617.0   \n",
              "4        6  2617.0 2015-11-02 2022-12-31 2616 days    D        2617.0   \n",
              "\n",
              "   mismatch  \n",
              "0         0  \n",
              "1         0  \n",
              "2         0  \n",
              "3         0  \n",
              "4         0  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This function count the number of obs you should have if you had a full time sequence\n",
        "Utils.check_length_time_serie(df_train_data, date_var, index = id).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7d18510c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>obs_id</th>\n",
              "      <th>forecast_id</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>3187477.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>6.370880e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42</td>\n",
              "      <td>2015-11-03</td>\n",
              "      <td>1309542.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>1.006306e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>42</td>\n",
              "      <td>2015-11-04</td>\n",
              "      <td>6998589.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>1.008557e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42</td>\n",
              "      <td>2015-11-05</td>\n",
              "      <td>5708558.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>1.017008e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42</td>\n",
              "      <td>2015-11-06</td>\n",
              "      <td>6931527.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>1.028142e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   site_id  timestamp     obs_id  forecast_id         value\n",
              "0       42 2015-11-02  3187477.0       1080.0  6.370880e+05\n",
              "1       42 2015-11-03  1309542.0       1080.0  1.006306e+06\n",
              "2       42 2015-11-04  6998589.0       1080.0  1.008557e+06\n",
              "3       42 2015-11-05  5708558.0       1080.0  1.017008e+06\n",
              "4       42 2015-11-06  6931527.0       1080.0  1.028142e+06"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "42bc870d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "List ids after resampling and adding full time sequence: [42, 43, 40, 41, 63, 66, 67, 68, 64, 65, 69, 70, 72, 73, 115, 119, 116, 117, 118, 59, 60, 62, 61, 112, 109, 110, 111, 8, 9, 25, 26, 46, 47, 48, 49, 106, 107, 100, 101, 102, 105, 50, 51, 52, 53, 108, 14, 10, 11, 12, 13, 22, 23, 57, 54, 58, 93, 94, 96, 98, 99, 92, 44, 45, 88, 87, 89, 90, 84, 85, 86, 78, 83, 228, 222, 223, 224, 225, 226, 227, 215, 229, 230, 273, 276, 271, 274, 275, 272, 74, 77, 76, 75, 218, 219, 221, 233, 234, 269, 270, 235, 236, 237, 216, 217, 204, 209, 261, 262, 263, 264, 265, 266, 267, 268, 232, 212, 213, 205, 206, 207, 208, 210, 211, 260, 259, 255, 256, 257, 231, 252, 254, 250, 251, 253, 238, 239, 240, 241, 243, 244, 245, 246, 247, 248, 249, 123, 124, 125, 126, 121, 122, 120, 127, 128, 129, 200, 201, 199, 141, 140, 135, 136, 139, 202, 203, 151, 149, 152, 146, 148, 150, 190, 191, 19, 167, 162, 173, 171, 172, 169, 170, 163, 164, 165, 143, 145, 142, 197, 194, 195, 196, 192, 193, 160, 161, 153, 154, 155, 156, 157, 158, 159, 198, 175, 174, 183, 184, 185, 186, 189, 181, 182, 130, 131, 134, 132, 176, 180, 177, 178, 280, 281, 277, 287, 288, 278, 279, 294, 295, 292, 293, 289, 290, 286, 285, 284, 298, 299, 300, 283, 297, 302, 301, 303, 304, 305, 282, 6, 7, 15, 16, 2, 1, 3, 5, 20, 21, 17, 18, 27, 33, 29, 32, 38, 39, 34]\n"
          ]
        }
      ],
      "source": [
        "print('List ids after resampling and adding full time sequence:', list(df_train_data[id].unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ca784d7",
      "metadata": {},
      "source": [
        "#### Weather data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7759c1a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "find_date, date_col found: ['timestamp']\n"
          ]
        }
      ],
      "source": [
        "# df_weather\n",
        "date_var = Utils.find_date(df_weather)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "af8a9f1a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "resample_data: variable temperature\n",
            "resample_data: variable temperature completed\n",
            "resample_data: variable distance\n",
            "resample_data: variable distance completed\n",
            "       timestamp  temperature  site_id   distance\n",
            "0     2015-01-01    -0.038168       51  28.196452\n",
            "1     2015-01-02     1.806015       51  28.194644\n",
            "2     2015-01-03     3.314179       51  28.102067\n",
            "3     2015-01-04     4.661654       51  28.089319\n",
            "4     2015-01-05     5.380741       51  28.615182\n",
            "...          ...          ...      ...        ...\n",
            "61557 2017-12-09          NaN       13        NaN\n",
            "61558 2017-12-10     4.650000       13  25.252279\n",
            "61559 2017-12-11     9.250000       13  24.200407\n",
            "61560 2017-12-12     7.650000       13  25.252279\n",
            "61561 2017-12-13     5.000000       13  24.200407\n",
            "\n",
            "[61562 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "# Resampling function aggregates data in a dataframe with a chosen function, that can vary depending on the variable\n",
        "# i.e. temperatures when aggregated should be averaged, consumption should be summed, dummy variables should be pick as 'first'\n",
        "\n",
        "df_weather[date_var] = df_weather[date_var].apply(lambda x: x.tz_localize(None))\n",
        "sampling = dt.timedelta(days=1)\n",
        "dict_grouping = {'temperature': 'mean', 'distance': 'mean'}\n",
        "df_resampled = Utils.resample_data(df_weather, id, date_var, sampling, dict_grouping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "0e412c15",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding sequence to serie 51 as 1 of 49\n",
            "Adding sequence to serie 50 as 2 of 49\n",
            "Adding sequence to serie 56 as 3 of 49\n",
            "Adding sequence to serie 57 as 4 of 49\n",
            "Adding sequence to serie 20 as 5 of 49\n",
            "Adding sequence to serie 21 as 6 of 49\n",
            "Adding sequence to serie 19 as 7 of 49\n",
            "Adding sequence to serie 22 as 8 of 49\n",
            "Adding sequence to serie 25 as 9 of 49\n",
            "Adding sequence to serie 26 as 10 of 49\n",
            "Adding sequence to serie 29 as 11 of 49\n",
            "Adding sequence to serie 28 as 12 of 49\n",
            "Adding sequence to serie 27 as 13 of 49\n",
            "Adding sequence to serie 30 as 14 of 49\n",
            "Adding sequence to serie 55 as 15 of 49\n",
            "Adding sequence to serie 52 as 16 of 49\n",
            "Adding sequence to serie 24 as 17 of 49\n",
            "Adding sequence to serie 23 as 18 of 49\n",
            "Adding sequence to serie 36 as 19 of 49\n",
            "Adding sequence to serie 35 as 20 of 49\n",
            "Adding sequence to serie 48 as 21 of 49\n",
            "Adding sequence to serie 47 as 22 of 49\n",
            "Adding sequence to serie 38 as 23 of 49\n",
            "Adding sequence to serie 37 as 24 of 49\n",
            "Adding sequence to serie 49 as 25 of 49\n",
            "Adding sequence to serie 33 as 26 of 49\n",
            "Adding sequence to serie 34 as 27 of 49\n",
            "Adding sequence to serie 46 as 28 of 49\n",
            "Adding sequence to serie 32 as 29 of 49\n",
            "Adding sequence to serie 42 as 30 of 49\n",
            "Adding sequence to serie 44 as 31 of 49\n",
            "Adding sequence to serie 39 as 32 of 49\n",
            "Adding sequence to serie 45 as 33 of 49\n",
            "Adding sequence to serie 40 as 34 of 49\n",
            "Adding sequence to serie 41 as 35 of 49\n",
            "Adding sequence to serie 5 as 36 of 49\n",
            "Adding sequence to serie 4 as 37 of 49\n",
            "Adding sequence to serie 3 as 38 of 49\n",
            "Adding sequence to serie 2 as 39 of 49\n",
            "Adding sequence to serie 6 as 40 of 49\n",
            "Adding sequence to serie 9 as 41 of 49\n",
            "Adding sequence to serie 8 as 42 of 49\n",
            "Adding sequence to serie 7 as 43 of 49\n",
            "Adding sequence to serie 12 as 44 of 49\n",
            "Adding sequence to serie 16 as 45 of 49\n",
            "Adding sequence to serie 17 as 46 of 49\n",
            "Adding sequence to serie 18 as 47 of 49\n",
            "Adding sequence to serie 10 as 48 of 49\n",
            "Adding sequence to serie 13 as 49 of 49\n",
            "add_seq: there are NO duplicates in sequence\n",
            "add_seq: there are NO duplicates when adding sequence\n",
            "Total serie to forecast: 143178\n"
          ]
        }
      ],
      "source": [
        "# Adding a full time sequence\n",
        "df_weather = Utils.add_seq(df_resampled, date_var, serie = id, freq = sampling, end_date=forecast_end_date, start_date='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "835dfe3e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expected length of sequence is OK \n",
            "     site_id   count  expected_obs\n",
            "0         2  2922.0        2922.0\n",
            "1         3  2922.0        2922.0\n",
            "2         4  2922.0        2922.0\n",
            "3         5  2922.0        2922.0\n",
            "4         6  2922.0        2922.0\n",
            "5         7  2922.0        2922.0\n",
            "6         8  2922.0        2922.0\n",
            "7         9  2922.0        2922.0\n",
            "8        10  2922.0        2922.0\n",
            "9        12  2922.0        2922.0\n",
            "10       13  2922.0        2922.0\n",
            "11       16  2922.0        2922.0\n",
            "12       17  2922.0        2922.0\n",
            "13       18  2922.0        2922.0\n",
            "14       19  2922.0        2922.0\n",
            "15       20  2922.0        2922.0\n",
            "16       21  2922.0        2922.0\n",
            "17       22  2922.0        2922.0\n",
            "18       23  2922.0        2922.0\n",
            "19       24  2922.0        2922.0\n",
            "20       25  2922.0        2922.0\n",
            "21       26  2922.0        2922.0\n",
            "22       27  2922.0        2922.0\n",
            "23       28  2922.0        2922.0\n",
            "24       29  2922.0        2922.0\n",
            "25       30  2922.0        2922.0\n",
            "26       32  2922.0        2922.0\n",
            "27       33  2922.0        2922.0\n",
            "28       34  2922.0        2922.0\n",
            "29       35  2922.0        2922.0\n",
            "30       36  2922.0        2922.0\n",
            "31       37  2922.0        2922.0\n",
            "32       38  2922.0        2922.0\n",
            "33       39  2922.0        2922.0\n",
            "34       40  2922.0        2922.0\n",
            "35       41  2922.0        2922.0\n",
            "36       42  2922.0        2922.0\n",
            "37       44  2922.0        2922.0\n",
            "38       45  2922.0        2922.0\n",
            "39       46  2922.0        2922.0\n",
            "40       47  2922.0        2922.0\n",
            "41       48  2922.0        2922.0\n",
            "42       49  2922.0        2922.0\n",
            "43       50  2922.0        2922.0\n",
            "44       51  2922.0        2922.0\n",
            "45       52  2922.0        2922.0\n",
            "46       55  2922.0        2922.0\n",
            "47       56  2922.0        2922.0\n",
            "48       57  2922.0        2922.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>count</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>td</th>\n",
              "      <th>freq</th>\n",
              "      <th>expected_obs</th>\n",
              "      <th>mismatch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2922.0</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>2921 days</td>\n",
              "      <td>D</td>\n",
              "      <td>2922.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>2922.0</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>2921 days</td>\n",
              "      <td>D</td>\n",
              "      <td>2922.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>2922.0</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>2921 days</td>\n",
              "      <td>D</td>\n",
              "      <td>2922.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>2922.0</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>2921 days</td>\n",
              "      <td>D</td>\n",
              "      <td>2922.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>2922.0</td>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>2921 days</td>\n",
              "      <td>D</td>\n",
              "      <td>2922.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   site_id   count        min        max        td freq  expected_obs  \\\n",
              "0        2  2922.0 2015-01-01 2022-12-31 2921 days    D        2922.0   \n",
              "1        3  2922.0 2015-01-01 2022-12-31 2921 days    D        2922.0   \n",
              "2        4  2922.0 2015-01-01 2022-12-31 2921 days    D        2922.0   \n",
              "3        5  2922.0 2015-01-01 2022-12-31 2921 days    D        2922.0   \n",
              "4        6  2922.0 2015-01-01 2022-12-31 2921 days    D        2922.0   \n",
              "\n",
              "   mismatch  \n",
              "0         0  \n",
              "1         0  \n",
              "2         0  \n",
              "3         0  \n",
              "4         0  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This function count the number of obs you should have if you had a full time sequence\n",
        "Utils.check_length_time_serie(df_weather, date_var, index = id).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "4eb29730",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding sequence to serie 51 as 1 of 49\n",
            "Adding sequence to serie 50 as 2 of 49\n",
            "Adding sequence to serie 56 as 3 of 49\n",
            "Adding sequence to serie 57 as 4 of 49\n",
            "Adding sequence to serie 20 as 5 of 49\n",
            "Adding sequence to serie 21 as 6 of 49\n",
            "Adding sequence to serie 19 as 7 of 49\n",
            "Adding sequence to serie 22 as 8 of 49\n",
            "Adding sequence to serie 25 as 9 of 49\n",
            "Adding sequence to serie 26 as 10 of 49\n",
            "Adding sequence to serie 29 as 11 of 49\n",
            "Adding sequence to serie 28 as 12 of 49\n",
            "Adding sequence to serie 27 as 13 of 49\n",
            "Adding sequence to serie 30 as 14 of 49\n",
            "Adding sequence to serie 55 as 15 of 49\n",
            "Adding sequence to serie 52 as 16 of 49\n",
            "Adding sequence to serie 24 as 17 of 49\n",
            "Adding sequence to serie 23 as 18 of 49\n",
            "Adding sequence to serie 36 as 19 of 49\n",
            "Adding sequence to serie 35 as 20 of 49\n",
            "Adding sequence to serie 48 as 21 of 49\n",
            "Adding sequence to serie 47 as 22 of 49\n",
            "Adding sequence to serie 38 as 23 of 49\n",
            "Adding sequence to serie 37 as 24 of 49\n",
            "Adding sequence to serie 49 as 25 of 49\n",
            "Adding sequence to serie 33 as 26 of 49\n",
            "Adding sequence to serie 34 as 27 of 49\n",
            "Adding sequence to serie 46 as 28 of 49\n",
            "Adding sequence to serie 32 as 29 of 49\n",
            "Adding sequence to serie 42 as 30 of 49\n",
            "Adding sequence to serie 44 as 31 of 49\n",
            "Adding sequence to serie 39 as 32 of 49\n",
            "Adding sequence to serie 45 as 33 of 49\n",
            "Adding sequence to serie 40 as 34 of 49\n",
            "Adding sequence to serie 41 as 35 of 49\n",
            "Adding sequence to serie 5 as 36 of 49\n",
            "Adding sequence to serie 4 as 37 of 49\n",
            "Adding sequence to serie 3 as 38 of 49\n",
            "Adding sequence to serie 2 as 39 of 49\n",
            "Adding sequence to serie 6 as 40 of 49\n",
            "Adding sequence to serie 9 as 41 of 49\n",
            "Adding sequence to serie 8 as 42 of 49\n",
            "Adding sequence to serie 7 as 43 of 49\n",
            "Adding sequence to serie 12 as 44 of 49\n",
            "Adding sequence to serie 16 as 45 of 49\n",
            "Adding sequence to serie 17 as 46 of 49\n",
            "Adding sequence to serie 18 as 47 of 49\n",
            "Adding sequence to serie 10 as 48 of 49\n",
            "Adding sequence to serie 13 as 49 of 49\n",
            "add_seq: there are NO duplicates in sequence\n",
            "add_seq: there are NO duplicates when adding sequence\n",
            "Total serie to forecast: 143178\n",
            "ten_year: asis temperatures do NOT contain any nan value\n"
          ]
        }
      ],
      "source": [
        "# Adding ten-year averages temperature to fill data until forecast_end_date\n",
        "freq = Utils.find_freq_in_dataframe(df_weather, date_var)\n",
        "temperature_list = ['temperature']\n",
        "df_weather_ten_year = Temperatures.ten_year(df_weather, id, date_var, freq, temperature_list, start_date ='', end_date=forecast_end_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cdc48fa",
      "metadata": {},
      "source": [
        "#### Additional data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6e08ec94",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>surface</th>\n",
              "      <th>sampling</th>\n",
              "      <th>base_temperature</th>\n",
              "      <th>monday_is_day_off</th>\n",
              "      <th>tuesday_is_day_off</th>\n",
              "      <th>wednesday_is_day_off</th>\n",
              "      <th>thursday_is_day_off</th>\n",
              "      <th>friday_is_day_off</th>\n",
              "      <th>saturday_is_day_off</th>\n",
              "      <th>sunday_is_day_off</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>207</td>\n",
              "      <td>7964.873347</td>\n",
              "      <td>30.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>15168.125971</td>\n",
              "      <td>30.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>74</td>\n",
              "      <td>424.340663</td>\n",
              "      <td>15.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>239</td>\n",
              "      <td>1164.822636</td>\n",
              "      <td>15.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>274</td>\n",
              "      <td>1468.246690</td>\n",
              "      <td>5.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   site_id       surface  sampling  base_temperature  monday_is_day_off  \\\n",
              "0      207   7964.873347      30.0              18.0              False   \n",
              "1        7  15168.125971      30.0              18.0              False   \n",
              "2       74    424.340663      15.0              18.0              False   \n",
              "3      239   1164.822636      15.0              18.0              False   \n",
              "4      274   1468.246690       5.0              18.0              False   \n",
              "\n",
              "   tuesday_is_day_off  wednesday_is_day_off  thursday_is_day_off  \\\n",
              "0               False                 False                False   \n",
              "1               False                 False                False   \n",
              "2               False                 False                False   \n",
              "3               False                 False                False   \n",
              "4               False                 False                False   \n",
              "\n",
              "   friday_is_day_off  saturday_is_day_off  sunday_is_day_off  \n",
              "0              False                 True               True  \n",
              "1              False                 True               True  \n",
              "2              False                 True               True  \n",
              "3              False                 True               True  \n",
              "4              False                 True               True  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df_metadata \n",
        "# does not contain a time series, therefore it cannot be resampled and do not need a full time sequence to check for NAs\n",
        "df_metadata.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a56ffd2",
      "metadata": {},
      "source": [
        "## Creating working dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6mGY36qeLgvf",
      "metadata": {
        "id": "6mGY36qeLgvf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "find_date, date_col found: ['timestamp']\n"
          ]
        }
      ],
      "source": [
        "# Site Ids available in all data dfs\n",
        "common_site_ids = list(set(set(df_weather_ten_year[id].unique()) & set(df_train_data[id].unique())))\n",
        "\n",
        "# Final df\n",
        "df_final = df_train_data[df_train_data[id].isin(common_site_ids)].copy()\n",
        "\n",
        "# Date\n",
        "date_var = Utils.find_date(df_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a5656c",
      "metadata": {},
      "source": [
        "#### Count NAs in y by id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "59ba6bca",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>obs_id</th>\n",
              "      <th>forecast_id</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>3187477.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>6.370880e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42</td>\n",
              "      <td>2015-11-03</td>\n",
              "      <td>1309542.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>1.006306e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>42</td>\n",
              "      <td>2015-11-04</td>\n",
              "      <td>6998589.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>1.008557e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42</td>\n",
              "      <td>2015-11-05</td>\n",
              "      <td>5708558.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>1.017008e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42</td>\n",
              "      <td>2015-11-06</td>\n",
              "      <td>6931527.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>1.028142e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   site_id  timestamp     obs_id  forecast_id         value\n",
              "0       42 2015-11-02  3187477.0       1080.0  6.370880e+05\n",
              "1       42 2015-11-03  1309542.0       1080.0  1.006306e+06\n",
              "2       42 2015-11-04  6998589.0       1080.0  1.008557e+06\n",
              "3       42 2015-11-05  5708558.0       1080.0  1.017008e+06\n",
              "4       42 2015-11-06  6931527.0       1080.0  1.028142e+06"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6a3889e4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    site_id  value\n",
              "0         2      0\n",
              "1         3      0\n",
              "2         5      0\n",
              "3         6      0\n",
              "4         7      0\n",
              "5         8      0\n",
              "6         9      0\n",
              "7        10      0\n",
              "8        12      0\n",
              "9        13      0\n",
              "10       16      0\n",
              "11       17      0\n",
              "12       18      0\n",
              "13       19      0\n",
              "14       20      0\n",
              "15       21      0\n",
              "16       22      0\n",
              "17       23      0\n",
              "18       25      0\n",
              "19       26      0\n",
              "20       27      0\n",
              "21       29      0\n",
              "22       32      0\n",
              "23       33      0\n",
              "24       34      0\n",
              "25       38      0\n",
              "26       39      0\n",
              "27       40      0\n",
              "28       41      0\n",
              "29       42      0\n",
              "30       44      0\n",
              "31       45      0\n",
              "32       46      0\n",
              "33       47      0\n",
              "34       48      0\n",
              "35       49      0\n",
              "36       50      0\n",
              "37       51      0\n",
              "38       52      0\n",
              "39       57      0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pivotna = pd.pivot_table(df_final[df_final[y].isna()], index=id, values = y, aggfunc='count').reset_index()\n",
        "pivotna.rename(columns={y: y + '_count_NA'})\n",
        "pivotna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6740bfb1",
      "metadata": {},
      "source": [
        "### Adding regressors to final dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5c112c5",
      "metadata": {},
      "source": [
        "#### Holidays"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2830270a",
      "metadata": {},
      "source": [
        "If you don't have specific holiday dataset, you can use the following general function by country that uses the holiday python package and adds to your dataframe a columns with a holiday dummy variable (0/1):\n",
        "\n",
        "    df_final = Regressors.add_holidays_by_country(df_final, date_var, country = 'France')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "805ebacf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min date: 2015-11-02 00:00:00\n",
            "Max date: 2022-12-31 00:00:00\n"
          ]
        }
      ],
      "source": [
        "df_final = Regressors.add_holidays_by_country(df_final, date_var, country='India')\n",
        "print('Min date:', df_final[date_var].min())\n",
        "print('Max date:', df_final[date_var].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5d3ce6b",
      "metadata": {},
      "source": [
        "#### Site leaves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "a97e9355",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "find_date, date_col found: ['timestamp']\n",
            "Min date: 2015-11-02 00:00:00\n",
            "Max date: 2022-12-31 00:00:00\n"
          ]
        }
      ],
      "source": [
        "dict_days_off = {'friday_is_day_off': 5, 'saturday_is_day_off': 6, 'sunday_is_day_off': 7}\n",
        "df_final = Regressors.merge_additional_days_off(df_final, df_metadata, id, dict_days_off)\n",
        "print('Min date:', df_final[date_var].min())\n",
        "print('Max date:', df_final[date_var].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ffa8f25",
      "metadata": {},
      "source": [
        "#### Additional metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "Vr1SWbRb9ZZx",
      "metadata": {
        "id": "Vr1SWbRb9ZZx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min date: 2015-11-02 00:00:00\n",
            "Max date: 2022-12-31 00:00:00\n"
          ]
        }
      ],
      "source": [
        "df_final = pd.merge(df_final, df_metadata[[id, \"surface\", \"base_temperature\"]], how=\"left\", on=[id], validate = 'm:1')\n",
        "print('Min date:', df_final[date_var].min())\n",
        "print('Max date:', df_final[date_var].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "395e6780",
      "metadata": {},
      "source": [
        "#### Other calendar variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "196089f6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min date: 2015-11-02 00:00:00\n",
            "Max date: 2022-12-31 00:00:00\n"
          ]
        }
      ],
      "source": [
        "df_final = Regressors.add_weekdays(df_final, date_var)\n",
        "df_final = Regressors.add_months(df_final, date_var)\n",
        "print('Min date:', df_final[date_var].min())\n",
        "print('Max date:', df_final[date_var].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c4213c3",
      "metadata": {},
      "source": [
        "#### Weather"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "f6187177",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "find_date, date_col found: ['timestamp']\n",
            "find_date, date_col found: ['timestamp']\n",
            "Min date: 2015-11-02 00:00:00\n",
            "Max date: 2022-12-31 00:00:00\n"
          ]
        }
      ],
      "source": [
        "df_final = Regressors.merge_weather(df_final, df_weather_ten_year, date_var, id)\n",
        "print('Min date:', df_final[date_var].min())\n",
        "print('Max date:', df_final[date_var].max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "d947c06d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min date: 2015-11-02 00:00:00\n",
            "Max date: 2022-12-31 00:00:00\n"
          ]
        }
      ],
      "source": [
        "df_final = Regressors.calculate_degree_days(df_final, base_temperature = \"base_temperature\", temperature = \"temperature\")\n",
        "print('Min date:', df_final[date_var].min())\n",
        "print('Max date:', df_final[date_var].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6743f041",
      "metadata": {},
      "source": [
        "#### Remove duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "fbcb2765",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "List ids in df_final after removing duplicates: [2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 29, 32, 33, 34, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 57]\n",
            "Min date: 2015-11-02 00:00:00\n",
            "Max date: 2022-12-31 00:00:00\n"
          ]
        }
      ],
      "source": [
        "df_final = df_final.drop_duplicates()\n",
        "print('List ids in df_final after removing duplicates:', list(df_final[id].unique()))\n",
        "assert df_final[df_final.duplicated()].count().sum() == 0, \"y should not contain duplicates\"\n",
        "print('Min date:', df_final[date_var].min())\n",
        "print('Max date:', df_final[date_var].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7809c54",
      "metadata": {},
      "source": [
        "#### Check regressor availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "4ea99f83",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['site_id', 'timestamp', 'obs_id', 'forecast_id', 'value', 'holidays',\n",
              "       'day_off', 'surface', 'base_temperature', 'wd_mon', 'wd_tue', 'wd_wed',\n",
              "       'wd_thu', 'wd_fri', 'wd_sat', 'wd_sun', 'month_01', 'month_02',\n",
              "       'month_03', 'month_04', 'month_05', 'month_06', 'month_07', 'month_08',\n",
              "       'month_09', 'month_10', 'month_11', 'month_12', 'temperature',\n",
              "       'distance', 'months_days', 'temperature_ten_year', 'temperature_asis',\n",
              "       'DDC_temperature', 'DDH_temperature'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "e7945831",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regressor holidays has all needed values\n",
            "Regressor day_off has all needed values\n",
            "Regressor surface has all needed values\n",
            "Regressor base_temperature has all needed values\n",
            "Regressor wd_mon has all needed values\n",
            "Regressor wd_tue has all needed values\n",
            "Regressor wd_wed has all needed values\n",
            "Regressor wd_thu has all needed values\n",
            "Regressor wd_fri has all needed values\n",
            "Regressor wd_sat has all needed values\n",
            "Regressor wd_sun has all needed values\n",
            "Regressor month_01 has all needed values\n",
            "Regressor month_02 has all needed values\n",
            "Regressor month_03 has all needed values\n",
            "Regressor month_04 has all needed values\n",
            "Regressor month_05 has all needed values\n",
            "Regressor month_06 has all needed values\n",
            "Regressor month_07 has all needed values\n",
            "Regressor month_08 has all needed values\n",
            "Regressor month_09 has all needed values\n",
            "Regressor month_10 has all needed values\n",
            "Regressor month_11 has all needed values\n",
            "Regressor month_12 has all needed values\n",
            "Latest filled available date for regressor temperature is 2017-12-31 00:00:00 \n",
            " expected is 2022-12-31 00:00:00\n",
            "Regressor holidays has all needed values\n",
            "Regressor day_off has all needed values\n",
            "Regressor surface has all needed values\n",
            "Regressor base_temperature has all needed values\n",
            "Regressor wd_mon has all needed values\n",
            "Regressor wd_tue has all needed values\n",
            "Regressor wd_wed has all needed values\n",
            "Regressor wd_thu has all needed values\n",
            "Regressor wd_fri has all needed values\n",
            "Regressor wd_sat has all needed values\n",
            "Regressor wd_sun has all needed values\n",
            "Regressor month_01 has all needed values\n",
            "Regressor month_02 has all needed values\n",
            "Regressor month_03 has all needed values\n",
            "Regressor month_04 has all needed values\n",
            "Regressor month_05 has all needed values\n",
            "Regressor month_06 has all needed values\n",
            "Regressor month_07 has all needed values\n",
            "Regressor month_08 has all needed values\n",
            "Regressor month_09 has all needed values\n",
            "Regressor month_10 has all needed values\n",
            "Regressor month_11 has all needed values\n",
            "Regressor month_12 has all needed values\n",
            "Latest filled available date for regressor temperature is 2017-12-31 00:00:00 \n",
            " expected is 2022-12-31 00:00:00\n",
            "Regressor temperature shows null values <= forecast_end_date. \n",
            " Regressor REMOVED\n",
            "Latest filled available date for regressor distance is 2017-12-31 00:00:00 \n",
            " expected is 2022-12-31 00:00:00\n",
            "Regressor distance shows null values <= forecast_end_date. \n",
            " Regressor REMOVED\n",
            "Regressor months_days has all needed values\n",
            "Latest filled available date for regressor temperature_ten_year is 2022-12-31 00:00:00 \n",
            " expected is 2022-12-31 00:00:00\n",
            "Regressor temperature_ten_year shows null values <= forecast_end_date. \n",
            " Regressor REMOVED\n",
            "Regressor temperature_asis has all needed values\n",
            "Latest filled available date for regressor DDC_temperature is 2017-12-31 00:00:00 \n",
            " expected is 2022-12-31 00:00:00\n",
            "Regressor DDC_temperature shows null values <= forecast_end_date. \n",
            " Regressor REMOVED\n",
            "Latest filled available date for regressor DDH_temperature is 2017-12-31 00:00:00 \n",
            " expected is 2022-12-31 00:00:00\n",
            "Regressor DDH_temperature shows null values <= forecast_end_date. \n",
            " Regressor REMOVED\n"
          ]
        }
      ],
      "source": [
        "# Temperatures have been filled, only temperature asis that is the composition between the actual temperature and ten year averages\n",
        "regressors_list = [ 'holidays',\n",
        "       'day_off', 'surface', 'base_temperature', 'wd_mon', 'wd_tue', 'wd_wed',\n",
        "       'wd_thu', 'wd_fri', 'wd_sat', 'wd_sun', 'month_01', 'month_02',\n",
        "       'month_03', 'month_04', 'month_05', 'month_06', 'month_07', 'month_08',\n",
        "       'month_09', 'month_10', 'month_11', 'month_12', 'temperature',\n",
        "       'distance', 'months_days', 'temperature_ten_year', 'temperature_asis',\n",
        "       'DDC_temperature', 'DDH_temperature']\n",
        "\n",
        "try:\n",
        "       Utils.check_regressors_availability(df_final, date_var, regressors_list, forecast_end_date)\n",
        "except:\n",
        "       Utils.remove_regressors_with_nan(df_final, date_var, regressors_list, forecast_end_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6dff377",
      "metadata": {},
      "source": [
        "# Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "4715ab4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.to_pickle(os.path.join(root, cfg_path.data_dir.output_path, 'df_final.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "bd0951d8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min date: 2015-11-02 00:00:00\n",
            "Max date: 2022-12-31 00:00:00\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>obs_id</th>\n",
              "      <th>forecast_id</th>\n",
              "      <th>value</th>\n",
              "      <th>holidays</th>\n",
              "      <th>day_off</th>\n",
              "      <th>surface</th>\n",
              "      <th>base_temperature</th>\n",
              "      <th>wd_mon</th>\n",
              "      <th>...</th>\n",
              "      <th>month_05</th>\n",
              "      <th>month_06</th>\n",
              "      <th>month_07</th>\n",
              "      <th>month_08</th>\n",
              "      <th>month_09</th>\n",
              "      <th>month_10</th>\n",
              "      <th>month_11</th>\n",
              "      <th>month_12</th>\n",
              "      <th>months_days</th>\n",
              "      <th>temperature_asis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>7390465.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.492533e+06</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6098.278376</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11/02</td>\n",
              "      <td>13.247917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10556.293605</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11/02</td>\n",
              "      <td>13.252083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12541.181277</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11/02</td>\n",
              "      <td>13.241667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>1413383.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>8.541479e+05</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9150.195373</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11/02</td>\n",
              "      <td>13.243750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15168.125971</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11/02</td>\n",
              "      <td>13.245833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   site_id  timestamp     obs_id  forecast_id         value  holidays  \\\n",
              "0        2 2015-11-02  7390465.0         26.0  1.492533e+06         0   \n",
              "1        3 2015-11-02        NaN          NaN           NaN         0   \n",
              "2        5 2015-11-02        NaN          NaN           NaN         0   \n",
              "3        6 2015-11-02  1413383.0        129.0  8.541479e+05         0   \n",
              "4        7 2015-11-02        NaN          NaN           NaN         0   \n",
              "\n",
              "   day_off       surface  base_temperature  wd_mon  ...  month_05  month_06  \\\n",
              "0        0   6098.278376              18.0       1  ...         0         0   \n",
              "1        0  10556.293605              18.0       1  ...         0         0   \n",
              "2        0  12541.181277              18.0       1  ...         0         0   \n",
              "3        0   9150.195373              18.0       1  ...         0         0   \n",
              "4        0  15168.125971              18.0       1  ...         0         0   \n",
              "\n",
              "   month_07  month_08  month_09  month_10  month_11  month_12  months_days  \\\n",
              "0         0         0         0         0         1         0        11/02   \n",
              "1         0         0         0         0         1         0        11/02   \n",
              "2         0         0         0         0         1         0        11/02   \n",
              "3         0         0         0         0         1         0        11/02   \n",
              "4         0         0         0         0         1         0        11/02   \n",
              "\n",
              "   temperature_asis  \n",
              "0         13.247917  \n",
              "1         13.252083  \n",
              "2         13.241667  \n",
              "3         13.243750  \n",
              "4         13.245833  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('Min date:', df_final[date_var].min())\n",
        "print('Max date:', df_final[date_var].max())\n",
        "df_final.head()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "AbKOiffyAql8",
        "6YxUycDC9p0h"
      ],
      "name": "Analysis (1).ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "2b8f5b14411d0017ed363cef4929504a7281087d06f1b18c01da6e951b937e80"
    },
    "kernelspec": {
      "display_name": "Python 3.7.7 ('forecasting_energy')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
